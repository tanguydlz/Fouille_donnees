---
title: "svm + ech ROSA"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(e1071)
library(dplyr)
library(caTools)
library(ROSE)
library(caret)
library(xgboost)

set.seed(123)
```


```{r}
load(file = "D:/Téléchargements/M2/fouille de données/Xtrain.Rdata")
load(file = "D:/Téléchargements/M2/fouille de données/ytrain.Rdata")
load(file = "D:/Téléchargements/M2/fouille de données/Xtest.Rdata")
load(file = "D:/Téléchargements/M2/fouille de données/ytest.Rdata")

TX= cbind(Xtrain,ytrain)
TXtrain = TX[ytrain==1,]
ech = sort(sample(nrow(TX), 5000))
p = TX[ech,]
TXtrain = rbind(TXtrain,p)
Tytrain = TXtrain$ytrain ; TXtrain = TXtrain[,-18]


ech = sort(sample(nrow(Xtrain), nrow(Xtrain)*.01))
ech2 = sort(sample(nrow(Xtest), nrow(Xtest)*.1))
Xtrain=Xtrain[ech,]
ytrain = ytrain[ech]

Xtest = Xtest[ech2,]
ytest = ytest[ech2]

Xytrain = cbind(Xtrain,ytrain)
table(Xytrain$ytrain)
```

méthode over et under sampling combiné avec le package ROSE

```{r}
Xytrain2 <- ovun.sample(ytrain ~ ., data = Xytrain, method = "both", p=0.5, seed=1)$data
table(Xytrain2$ytrain)

Xtrain2 = Xytrain2[,1:17]
ytrain2 = Xytrain2[,18]
```


SVM avec cette méthode

```{r}
model2 <- svm(Xtrain2, ytrain2, scale=T, type= "C-classification",kernel='linear')
summary(model2)

#Prédiction sur les données test
pred2 = predict(model2, newdata = Xtest)
#Matrice de confusion
cm = table(pred2, ytest); cm
#Taux d'erreur
err2 = (cm[1,2] + cm[2,1])/sum(cm); err2

roc.curve(ytest, pred2)
```


méthode ROSE du package
Les données générées par le suréchantillonnage ont prévu une quantité d'observations répétées. 
Les données générées par le sous-échantillonnage sont privées d'informations importantes par rapport aux données d'origine. 
Ce qui entraéne des inexactitudes dans les performances résultantes. Pour faire face à ces problémes, ROSE nous aide à générer des données de maniére synthétique également. 
Les données générées par ROSE sont considérées comme fournissant une meilleure estimation des données originales.

```{r}
Xytrain3 <- ROSE(ytrain ~ ., data = Xytrain, seed = 1)$data
table(Xytrain3$ytrain)
```

Cet ensemble nous fournit également des méthodes pour vérifier l'exactitude du modéle en utilisant la méthode de bagging et holdout.

Cela nous permet de nous assurer que nos prévisions résultantes ne souffrent pas d'une variance élevée.

```{r}
ROSE.holdout <- ROSE.eval(ytrain ~ ., data = Xytrain3, learner = svm, method.assess = "holdout", extr.pred = function(obj)obj, seed = 1)
ROSE.holdout
```

Nous constatons que notre précision se maintient à ~ 0,89 et montre que nos prévisions ne souffrent pas d'une variance élevée.

```{r}
#leave-K-out cross validation trop long
# ROSE.cv <- ROSE.eval(ytrain ~ ., data = Xytrain3, learner = svm, method.assess = "LKOCV", extr.pred = function(obj)obj, seed = 1)
# ROSE.cv
```

```{r}
Xtrain = Xytrain3[,1:17]
ytrain = Xytrain3[,18]
```



SVM avec la méthode d'échantillonage ROSE
```{r}
##########Kernel linéaire
model <- svm(Xtrain, ytrain, scale=T, type= "C-classification",kernel='linear')
summary(model)
```

```{r}
#Prédiction sur les données test
pred = predict(model, newdata = Xtest)
#Matrice de confusion
cm = table(pred, ytest); cm
#Taux d'erreur
err = (cm[1,2] + cm[2,1])/sum(cm); err

roc.curve(ytest, pred)
```

```{r}
#F mesure
cf <- confusionMatrix(pred, ytest, mode = "prec_recall", positive = '1')
print(cf)
```

bien meilleur avec méthode rose que Combined under/over

```{r}
########Kernel radial
model_rad <- svm(Xtrain, ytrain, scale=T, type= "C-classification",kernel='radial')
summary(model_rad)
```

```{r}
#Prédiction sur les données test
pred = predict(model_rad, newdata = Xtest)
#Matrice de confusion
cm = table(pred, ytest); cm
#Taux d'erreur
err = (cm[1,2] + cm[2,1])/sum(cm); err

roc.curve(ytest, pred)
```


```{r}
#F mesure
cf <- confusionMatrix(pred, ytest, mode = "prec_recall", positive = '1')$byClass[7]
print(cf)
```


SVM avec les vraies données pour la classe minoritaire

```{r}
##########Kernel linéaire
model <- svm(TXtrain, Tytrain, scale=T, type= "C-classification",kernel='linear')
summary(model)
```

```{r}
#Prédiction sur les données test
pred = predict(model, newdata = Xtest)
#Matrice de confusion
cm = table(pred, ytest); cm
#Taux d'erreur
err = (cm[1,2] + cm[2,1])/sum(cm); err

roc.curve(ytest, pred)
```

```{r}
#F mesure
cf <- confusionMatrix(pred, ytest, mode = "prec_recall", positive = '1')
print(cf)
```


```{r}
#Optimisation de Gamma et C
tuned = tune.svm(x=TXtrain,
                 y=Tytrain, 
                 scale=T, type = "C-classification", kernel='linear',
                 cost = 10^(-1:2), 
                 gamma = c(0.1, 1, 10),
                 tunecontrol=tune.control(cross=2))
tuned$performances
```

```{r}
svmfit = tuned$best.model
#Prédiction sur les données test
pred = predict(svmfit, newdata = Xtest)
#Matrice de confusion
cm = table(pred, ytest); cm
#Taux d'erreur
err = (cm[1,2] + cm[2,1])/sum(cm); err

roc.curve(ytest, pred)
```

```{r}
#F mesure
cf <- confusionMatrix(pred, ytest, mode = "prec_recall", positive = '1')
print(cf)
```


```{r}
#Optimisation de Gamma et C
model2=svm(Xtrain, ytrain, scale=T,cost=1, gamma=0.1, type= "C-classification",kernel='linear')
```

```{r}
#Prédiction sur les données test
pred = predict(model2, newdata = Xtest)
#Matrice de confusion
cm = table(pred, ytest); cm
#Taux d'erreur
err = (cm[1,2] + cm[2,1])/sum(cm); err

roc.curve(ytest, pred)
```

```{r}
#F mesure
cf <- confusionMatrix(pred, ytest, mode = "prec_recall", positive = '1')
print(cf)
```


##########################################################################
############## XGBOOST Gradient Boosting #################################
##########################################################################

```{r}
rm(list = ls())
```


```{r}
load(file = "D:/Téléchargements/M2/fouille de données/Xtrain.Rdata")
load(file = "D:/Téléchargements/M2/fouille de données/ytrain.Rdata")
load(file = "D:/Téléchargements/M2/fouille de données/Xtest.Rdata")
load(file = "D:/Téléchargements/M2/fouille de données/ytest.Rdata")

TX= cbind(Xtrain,ytrain)
TXtrain = TX[ytrain==1,]
ech = sort(sample(nrow(TX), 5000))
p = TX[ech,]
TXtrain = rbind(TXtrain,p)
Tytrain = TXtrain$ytrain ; TXtrain = TXtrain[,-18]
Txy=cbind(TXtrain,Tytrain)

rm(ech,p,TXtrain,Tytrain,TX)

ech = sort(sample(nrow(Xtrain), nrow(Xtrain)*.25))
ech2 = sort(sample(nrow(Xtest), nrow(Xtest)*.1))
XYtrain=cbind(Xtrain[ech,],ytrain[ech])
colnames(XYtrain)[18] = "ytrain"

XYtest = cbind(Xtest[ech2,], ytest[ech2])
colnames(XYtest)[18] = "ytest"

table(XYtrain$ytrain)

rm(ech,ech2)
```



```{r}
xgb_Xtrain = xgb.DMatrix(as.matrix(Txy %>% select(-Tytrain)))
xgb_ytrain = Txy$Tytrain

#Recode en char car XGboost ne prend pas 0 et 1 en binaire
xgb_ytrain = recode(xgb_ytrain, "0"="A", "1"="B")

xgb_Xtest = xgb.DMatrix(as.matrix(XYtest %>% select(-ytest)))
xgb_ytest = XYtest$ytest
```

On va donc commencer par définir un objet trainControl, qui permet de contrôler la manière dont se fait l’entraînement du modèle, assuré par la fonction train().

Ici, nous choisissons une validation croisée (method = ‘cv’) à 5 folds (number = 5). On choisit également d’autoriser la parallélisation des calculs (allowParallel = TRUE), de réduire la verbosité (verboseIter = FALSE).

```{r}
xgb_trcontrol = trainControl(method = "cv", number = 2, allowParallel = TRUE, 
    verboseIter = FALSE, returnData = FALSE, summaryFunction = twoClassSummary,classProbs = TRUE)
```

On définit ensuite une grille de paramètres du modèle XGBoost appelée xgbGrid

```{r}
xgbGrid <- expand.grid(nrounds = c(100,200),  
                       max_depth = c(3, 5, 10, 15, 20),
                       colsample_bytree = seq(0.5, 0.9, length.out = 5),
                       ## valeurs par défaut : 
                       eta = 0.1,
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )
```

nrounds: nombre d’itérations de boosting à effectuer. Plus il est grand, et plus c’est lent
max_depth: profondeur d’arbre maximale. Risque d’over-fit si trop grand, et d’under-fit si trop petit
colsample_bytree: pourcentage des colonnes pris pour construire un arbre (rappelle-toi, un arbre est construit avec un sous-ensemble des données: lignes et colonnes)
eta: ou learning rate, ce paramètre contrôle la vitesse à laquelle on convergence lors de la descente du gradient fonctionnelle (par défaut = 0.3)
gamma: diminution minimale de la valeur de la loss (fonction objectif) pour prendre la décision de partitionner une feuille

```{r}
xgb_model = train(xgb_Xtrain, xgb_ytrain, trControl = xgb_trcontrol, tuneGrid = xgbGrid, 
    method = "xgbTree",metric = "ROC")
```

```{r}
xgb_model$bestTune
```

```{r}
pred = predict(xgb_model, xgb_Xtest)
pred = recode(pred, "A"=0,"B"=1)
pred=as.factor(pred)
#Matrice de confusion
cm = table(pred, xgb_ytest); cm
#Taux d'erreur
err = (cm[1,2] + cm[2,1])/sum(cm); err

roc.curve(xgb_ytest, pred)
```

```{r}
#F mesure
cf <- confusionMatrix(pred, xgb_ytest, mode = "prec_recall", positive = '1')$byClass[7]
print(round(cf*100,2))
```

######### Test avec méthode d'échantillonage over/undersampling avec autant de classe minoritaire que majoritaire

```{r}
XYtrain <- ovun.sample(ytrain ~ ., data = XYtrain, method = "both", p=0.5, seed=1)$data
table(XYtrain$ytrain)
```


```{r}
xgb_Xtrain = xgb.DMatrix(as.matrix(XYtrain %>% select(-ytrain)))
xgb_ytrain = XYtrain$ytrain

#Recode en char car XGboost ne prend pas 0 et 1 en binaire
xgb_ytrain = recode(xgb_ytrain, "0"="A", "1"="B")

xgb_Xtest = xgb.DMatrix(as.matrix(XYtest %>% select(-ytest)))
xgb_ytest = XYtest$ytest
```

```{r}
xgb_trcontrol = trainControl(method = "cv", number = 2, allowParallel = TRUE, 
    verboseIter = FALSE, returnData = FALSE, summaryFunction = twoClassSummary,classProbs = TRUE)
```


```{r}
xgbGrid <- expand.grid(nrounds = c(100,200),  
                       max_depth = c(3, 5, 10, 15, 20),
                       colsample_bytree = seq(0.5, 0.9, length.out = 5),
                       ## valeurs par défaut : 
                       eta = 0.1,
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )
```


```{r}
xgb_model = train(xgb_Xtrain, xgb_ytrain, trControl = xgb_trcontrol, tuneGrid = xgbGrid, 
    method = "xgbTree",metric = "ROC")
```

```{r}
xgb_model$bestTune
```

```{r}
pred = predict(xgb_model, xgb_Xtest)
pred = recode(pred, "A"=0,"B"=1)
pred=as.factor(pred)
#Matrice de confusion
cm = table(pred, xgb_ytest); cm
#Taux d'erreur
err = (cm[1,2] + cm[2,1])/sum(cm); err

roc.curve(xgb_ytest, pred)
```


```{r}
#F mesure
cf <- confusionMatrix(pred, xgb_ytest, mode = "prec_recall", positive = '1')$byClass[7]
print(round(cf*100,2))
```
